\documentclass[a4paper, 11pt]{exam}
\usepackage{titling}
\usepackage{algorithm,algorithmic,amsmath}
\newcommand{\subtitle}[1]{%
  \posttitle{%
    \par\end{center}
    \begin{center}\large#1\end{center}
    }%
}

\usepackage{url}
\usepackage{amsmath,amsthm,enumitem,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\renewcommand{\labelenumii}{\roman{enumii}}

\title{Homework Assignment 3}
\subtitle{CS/ECE 6810: Computer Architecture \\
October 31,2018
\\
Name: Jake Pitkin

UID: u0891770}

\author{ \\
\textbf{OoO and Cache Optimization}}
\date{Due Date: November 11, 2018.\\
120 points}

\begin{document}
\maketitle

\begin{enumerate}


\item \textbf{OoO Processor and Cache Parameters.} Please specify each of the following statement is True or False and explain why. 

\begin{enumerate}
	\item Instructions read all source operands from the register file in the Tomasuloâ€™s algorithm.\textbf{(2 points)}
	
	\fbox{\parbox{\linewidth}{\textbf{False.} A source operand could also be read from a reservation station as Tomasulo's algorithm uses these for register renaming.}}
	
	\item In a processor with hardware speculation, a store can always be committed as soon
	as its effective address and source value are available in the load-store queue.\textbf{(2 points)}
	
	\fbox{\parbox{\linewidth}{\textbf{True.} Effective address is required for dependence check and we check availability of operands every cycle to determine if we can execute the store operation.}}
	
	\item If cache block size remains same, but the number of cache blocks doubles, the compulsory misses remain the same.\textbf{(2 points)}
	
	\fbox{\parbox{\linewidth}{\textbf{False.} A compulsory miss is the first access to a block. With twice as many cache blocks, we increase the number of possible compulsory misses. Increasing the cache block size instead could decrease the number of compulsory misses.}}
	
	\item  If the cache capacity is fixed but the block size is increased, the miss rate will not change.\textbf{(2 points)}

	\fbox{\parbox{\linewidth}{\textbf{False.} The number of compulsory misses will decrease as the block size is increasing. Additionally, changing the cache design will most likely change the conflict miss rate (depending on the access pattern of a given program) compared to the miss rate of the original design.}}
	
	\item Write-through caches use write allocate mechanism to prevent writing dirty blocks to lower memory levels.\textbf{(2 points)}
	
	\fbox{\parbox{\linewidth}{\textbf{False.} A write-through cache typically uses no-write allocate. No real benefit to cache what was written as a future matching write (when using write-through) will write through to memory regardless.}}
\end{enumerate}



\item \textbf {Memory Hierarchy.}
Consider a processor with the following memory
organization: L1 Cache, L2 Cache, L3 Cache and main memory. Each cache stores both tags
and data. The data and tag arrays are going to be accessed with the same index value. Assume
that the processor does serial tag/data look-up (first tag lookup and then data access) for L2
and L3 caches and parallel tag/data look-up for L1 cache. The table given below provides the
time take to access the tag and data arrays in CPU cycles. 
Find the number of cycles required to complete 2000 load instructions accessing this
hierarchy.\textbf{(15 points)}

\begin{center}
	\begin{tabular}{ |c|c|c|c| } 
		\hline
		\textbf{Level}& \textbf{Tag Access}& \textbf{Data Access} & \textbf{Hit Rate}\\ 
		\hline
		L1 (32 KB) & 1 & -  & 40\%\ \\ 
		L2 (1 MB) & 4 & 12  & 50\% \\ 
		L3 (8 MB) & 25 & 90  & 80\%\\ 
		\hline
		Main Memory & - & 500  & - \\ 
		\hline
	\end{tabular}
\end{center}

\begin{align*}
L1 \ cycles &= instructions * access \ time * L1_{hit} \\ 
            &= 2,000 * 1 * 0.4 \\
            &= 800 \\
L2 \ cycles &= instructions * access \ time * L1_{miss} * L2_{hit} \\
            &= 2,000 * (1 + 4 + 12) * 0.6 * 0.5\\
            &= 8,160 \\
L3 \ cycles &= instructions * access \ time * L1_{miss} * L2_{miss} * L3_{hit}\\
            &= 2,000 * (1 + 4 + 25 + 90) * 0.6 * 0.5 * 0.8\\
            &= 57,600\\
Main \ Memory \ Cycles &= instructions * access \ time * L1_{miss} * L2_{miss} * L3_{miss} \\
                       &= 2,000 * (1 + 4 + 25 + 500) * 0.6 * 0.5 * 0.2\\
                       &= 63,600\\
Total \ cycles &= L1_{cycles} + L2_{cycles} + L3_{cycles} + Memory_{cycles}\\
               &= 800 + 8,160 + 57,600 + 63,600 \\
               &= 130,160 \ cycles                      
\end{align*}

\fbox{\parbox{\linewidth}{\textbf{Answer:} 130,160 cycles to complete 2000 load instructions.}}

\item \textbf{Cache Hit Rate.}
Consider a 256K main memory system with a direct mapped cache that stores up to 4 blocks. Each cache block comprises 4 words. The replacement policy is MRU and at the beginning cache is empty. Compute the hit rate for the following stream of addresses generated by the processor.(All memory addresses are in decimal format and each address refer to a word).\textbf{(10 points)}

\texttt{170 , 257, 168, 246, 176, 175, 176, 177, 175, 176, 177, 175, 176, 177, 176, 175, 174, 173, 172, 171, 170, 169, 168, 167, 168, 165, 164}



\item \textbf{Cache Performance.}
Consider the following  pseudo code; suppose that \textbf{X} and \textbf{Y} are allocated as contiguous integer arrays in memory and are aligned to the 4KB boundaries.
Assume \textbf{k} and \textbf{l} are allocated in the register file with no need for memory accesses.
We execute the code on a machine where the integer type (\textbf{int}) is 4 bytes wide.

	\begin{algorithm}
		\textbf{\#define M 1024} \\
		\textbf{int X[M*M];} \\
		\textbf{int Y[M*M];} \\
		\textbf{int k, l;}
		\begin{algorithmic}	
			\FOR{$(k = 0; k < M; k++)$}
			\FOR{$(l = 0; l < M; l++)$}
			\STATE \texttt{Y[l*M+k] = X[k*M+l];}
			\ENDFOR
			\ENDFOR
		\end{algorithmic}
	\end{algorithm}

\begin{enumerate}
\item Consider a 4KB 2-way set-associative cache architecture while cache block size is 32-byte (8-word) and the replacement policy is LRU. Compute the hit rate of data accesses generated by \texttt{load}s and \texttt{store}s to \textbf{X} and \textbf{Y}?\textbf{(15 points)}




\item Consider a 4KB fully associative cache architecture with 32-byte blocks. The replacement policy is LRU. Rewrite the code to remove  all of the non-compulsory misses. (You need to ensure the new code generate the exact same output in the main memory.You are allowed to add a nested for loop to the code if necessary.) Please provide explanation on how the new code can remove those misses.\textbf{(15 points)}


\end{enumerate}



\item \textbf {Cache Addressing.} Consider a processor using 3 cache levels. Level-1 cache is a
32KB direct mapped cache with 16B blocks used for both instructions and data. Level-2 is a
256KB, 2-way set associative cache with 64B cache lines. Level-3 is a
1MB, 4-way set associative cache with 64B cache lines. Assume that the processor can
address up to 16GB of main memory.  Compute the size of the tag arrays in KB for each level.\textbf{(15 points)}





\item \textbf{Cache and Memory Model using CACTI }

CACTI (\url{http://www.cs.utah.edu/~rajeev/cacti7/}) is an integrated cache and memory model for access time, cycle time, area, leakage, and dynamic power. You are asked to use CACTI 7 for investigating the impact of small and simple caches using a 22nm CMOS technology node. Consider a processor using 2 cache levels. Level-1 cache is a 32 KB direct mapped cache with 16B blocks used for both instructions and data. Level-2 is a 1MB, 4-way set associative cache with 64B cache lines. Assume that the processor can address up to 2GB of main memory. Assume that both of the Level-1 and Level-2 caches are single bank.
\begin{enumerate}
	\item Compare the access time, energy, leakage power, and area of the caches mentioned above.\textbf{(10 points)} 
    \item Investigate the impact of varying associativity for 1, 2, and 8 on the access time, energy, leakage, and area of the Level-2 cache.\textbf{(10 points)}

\end{enumerate}

\item {\bf Bonus Question.}   
The table below lists a sequence of loads and stores in the load-store queue (LSQ), when their one/two input operands are made available, and their computed effective addresses.
Find when the address calculation happens for each load/store and when each load/store accesses the data memory.
The processor assumes that loads do not depend on prior stores and issues loads speculatively.
If the speculation is incorrect, the load must be re-issued.
Assume that there are enough memory ports that you don't have to worry about structural hazards.{\bf(20 points)}

\begin{table}[h!]
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|c|}
			\hline
			LD/ST & The register for the & The register that & The calculated & Addr calculation & Data memory \\
			& address calculation  & must be stored    & effective addr & happens          & accessed    \\
			& is made available    & into memory is    & (hexadecimal)  &                  &             \\
			&                      & made available    &                &                  &             \\
			\hline
			\hline
			LD    & 6                    & -                 & 12345678       &                  &             \\
			\hline
			ST    & 9                    & 8                 & 87654321       &                  &             \\
			\hline
			LD    & 1                    & -                 & 87654321       &                  &             \\
			\hline
			LD    & 5                    & -                 & 12345678       &                  &             \\
			\hline
			ST    & 23                   & 30                & 87654321       &                  &             \\
			\hline
			LD    & 4                    & -                 & 87654321       &                  &             \\
			\hline
		\end{tabular}
	\end{center}
\end{table}




\end{enumerate}


\end{document}